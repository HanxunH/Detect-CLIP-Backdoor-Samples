epochs: 32
tokenizer: 'RN50'
lr: 0.001
weight_decay: 0.2
warmup_epochs: 4.25
log_frequency: 200
min_lr: 0
sync_bn: false
lr_schedule: cosine
snapshot_epoch: 32
eval_every_epoch: 1
amp: true
zero_shot_templates: 'OPENAI_IMAGENET_TEMPLATES'
class_names: 'IMAGENET_CLASSNAMES'

criterion:
  name: OpenClipLoss
  gather_distributed: true

optimizer:
  name: AdamW
  lr: $lr
  weight_decay: 0.0
  betas: 
  - 0.9
  - 0.999
  eps: 1.0e-8

vision_model:
  name: VisionTransformerOpenCLIP
  image_size: 224
  output_dim: 512
  layers: 12
  width: 768
  heads: 12
  patch_size: 16
  get_features: true
  
text_model:
  name: TextTransformer
  context_length: 77
  vocab_size: 49408
  width: 512
  heads: 8
  layers: 12
  output_dim: 512
  
dataset:
  name: DatasetGenerator
  train_bs: 256
  eval_bs: 256
  n_workers: 8
  train_d_type: ConceptualCaptionsDataset
  test_d_type: ImageFolder
  train_tf_op: CLIPCC3M
  test_tf_op: CLIPCC3M
  train_path: TODO: Set the path to the Conceptual Captions dataset
  test_path: TODO: Set the path to the ImageNet dataset
  tokenizer: $tokenizer
  collate_fn:
    name: None
